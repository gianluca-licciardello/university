{"cells":[{"cell_type":"markdown","metadata":{"id":"aUpniP_IFgd9"},"source":["CoNLL-2003 dataset task demonstrates the labeling of tokens for named entity recognition (NER), part-of-speech (POS) tagging, and chunking. Each component of the JSON object corresponds to a different layer of annotation for the sentence:\n","\n","1. **Tokens**: These are the individual words or punctuation marks from the text. In this case, the sentence \"EU rejects German call to boycott British lamb.\" is split into tokens:\n","   - \"EU\"\n","   - \"rejects\"\n","   - \"German\"\n","   - \"call\"\n","   - \"to\"\n","   - \"boycott\"\n","   - \"British\"\n","   - \"lamb\"\n","   - \".\"\n","\n","2. **POS Tags**: This array contains the POS tags corresponding to each token. The tags are encoded as numbers, each representing a specific part of speech (like noun, verb, adjective). These numbers usually correspond to a tagging scheme such as the Penn Treebank POS tags:\n","   - \"EU\" is tagged as 22, which represents a proper noun.\n","   - \"rejects\" is tagged as 42, indicating a verb in present tense.\n","   - And so forth.\n","\n","3. **Chunk Tags**: This array indicates phrase chunk boundaries and types (like NP for noun phrase, VP for verb phrase). Each number again corresponds to a specific type of phrase or boundary in a predefined scheme:\n","   - \"EU\" is part of a noun phrase, hence 11.\n","   - \"rejects\" begins a verb phrase, indicated by 21.\n","   - The chunk tags help in parsing the sentence into linguistically meaningful phrases.\n","\n","4. **NER Tags**: These tags are used for named entity recognition. They identify whether each token is part of a named entity (like a person, location, organization) and the type of entity:\n","   - \"EU\" is tagged as 3, denoting an organization.\n","   - \"German\" and \"British\" are tagged as 7, indicating nationality or ethnicity.\n","   - Other tokens are tagged as 0, meaning they are not recognized as part of any named entity."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lr7rTDQnFgeG"},"outputs":[],"source":["#!pip install uv\n","#!uv pip install numpy pandas torch transformers datasets scikit-learn umap-learn matplotlib seaborn"]},{"cell_type":"markdown","metadata":{"id":"B1-XJhBiFgeI"},"source":["Homework:\n","Load a NER dataset (e.g. CoNLL-2003) using the script provided below.\n","# Instructions\n","1. download the **conll2003** from the following [link](\"https://data.deepai.org/conll2003.zip\")\n","2. unzip the file\n","3. download the glove embeddings from [link](\"https://huggingface.co/datasets/SLU-CSCI4750/glove.6B.100d.txt/resolve/main/glove.6B.100d.txt.gz\")\n","4. unzip the glove embeddings file\n","5. update the constants in the code below to point to the correct file paths on your machine"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"OvpdR3GoF8nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRUdDRj5FgeJ"},"outputs":[],"source":["# basic python data science tooling\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","\n","from datasets import (\n","    Dataset,\n","    DatasetDict,\n","    Features,\n","    Sequence,\n","    ClassLabel,\n","    Value,\n",")\n","\n","# constants for config\n","LOCAL_DIR = \"/content/drive/MyDrive/Data Science/Deep learning for natural language processing/assignments/\"\n","GLOVE_EMBEDS_PATH = '/content/drive/MyDrive/Data Science/Deep learning for natural language processing/assignments/glove.6B.100d.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4NxjOggFgeO"},"outputs":[],"source":["train_file = os.path.join(LOCAL_DIR, \"train.txt\")\n","valid_file = os.path.join(LOCAL_DIR, \"valid.txt\")\n","test_file = os.path.join(LOCAL_DIR, \"test.txt\")\n","\n","pos_names = [\n","    '\"',\n","    \"''\",\n","    \"#\",\n","    \"$\",\n","    \"(\",\n","    \")\",\n","    \",\",\n","    \".\",\n","    \":\",\n","    \"``\",\n","    \"CC\",\n","    \"CD\",\n","    \"DT\",\n","    \"EX\",\n","    \"FW\",\n","    \"IN\",\n","    \"JJ\",\n","    \"JJR\",\n","    \"JJS\",\n","    \"LS\",\n","    \"MD\",\n","    \"NN\",\n","    \"NNP\",\n","    \"NNPS\",\n","    \"NNS\",\n","    \"NN|SYM\",\n","    \"PDT\",\n","    \"POS\",\n","    \"PRP\",\n","    \"PRP$\",\n","    \"RB\",\n","    \"RBR\",\n","    \"RBS\",\n","    \"RP\",\n","    \"SYM\",\n","    \"TO\",\n","    \"UH\",\n","    \"VB\",\n","    \"VBD\",\n","    \"VBG\",\n","    \"VBN\",\n","    \"VBP\",\n","    \"VBZ\",\n","    \"WDT\",\n","    \"WP\",\n","    \"WP$\",\n","    \"WRB\",\n","]\n","\n","chunk_names = [\n","    \"O\",\n","    \"B-ADJP\",\n","    \"I-ADJP\",\n","    \"B-ADVP\",\n","    \"I-ADVP\",\n","    \"B-CONJP\",\n","    \"I-CONJP\",\n","    \"B-INTJ\",\n","    \"I-INTJ\",\n","    \"B-LST\",\n","    \"I-LST\",\n","    \"B-NP\",\n","    \"I-NP\",\n","    \"B-PP\",\n","    \"I-PP\",\n","    \"B-PRT\",\n","    \"I-PRT\",\n","    \"B-SBAR\",\n","    \"I-SBAR\",\n","    \"B-UCP\",\n","    \"I-UCP\",\n","    \"B-VP\",\n","    \"I-VP\",\n","]\n","\n","ner_names = [\n","    \"O\",\n","    \"B-PER\",\n","    \"I-PER\",\n","    \"B-ORG\",\n","    \"I-ORG\",\n","    \"B-LOC\",\n","    \"I-LOC\",\n","    \"B-MISC\",\n","    \"I-MISC\",\n","]\n","\n","\n","def parse_conll(path: str):\n","    \"\"\"Parse a CoNLL-2003 file into a list of examples.\"\"\"\n","    examples = []\n","    tokens, pos_tags, chunk_tags, ner_tags = [], [], [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            if line.startswith(\"-DOCSTART-\") or line.strip() == \"\":\n","                if tokens:\n","                    examples.append(\n","                        {\n","                            \"tokens\": tokens,\n","                            \"pos_tags\": pos_tags,\n","                            \"chunk_tags\": chunk_tags,\n","                            \"ner_tags\": ner_tags,\n","                        }\n","                    )\n","                    tokens, pos_tags, chunk_tags, ner_tags = [], [], [], []\n","            else:\n","                splits = line.rstrip().split(\" \")\n","                tokens.append(splits[0])\n","                pos_tags.append(splits[1])\n","                chunk_tags.append(splits[2])\n","                ner_tags.append(splits[3])\n","    if tokens:\n","        examples.append(\n","            {\n","                \"tokens\": tokens,\n","                \"pos_tags\": pos_tags,\n","                \"chunk_tags\": chunk_tags,\n","                \"ner_tags\": ner_tags,\n","            }\n","        )\n","    return examples\n","\n","\n","def as_dataset(examples, features: Features):\n","    ids = []\n","    tokens_col, pos_col, chunk_col, ner_col = [], [], [], []\n","    for i, ex in enumerate(examples):\n","        ids.append(str(i))\n","        tokens_col.append(ex[\"tokens\"])\n","        pos_col.append(ex[\"pos_tags\"])\n","        chunk_col.append(ex[\"chunk_tags\"])\n","        ner_col.append(ex[\"ner_tags\"])\n","    return Dataset.from_dict(\n","        {\n","            \"id\": ids,\n","            \"tokens\": tokens_col,\n","            \"pos_tags\": pos_col,\n","            \"chunk_tags\": chunk_col,\n","            \"ner_tags\": ner_col,\n","        },\n","        features=features,\n","    )\n","\n","\n","features = Features(\n","    {\n","        \"id\": Value(\"string\"),\n","        \"tokens\": Sequence(Value(\"string\")),\n","        \"pos_tags\": Sequence(ClassLabel(names=pos_names)),\n","        \"chunk_tags\": Sequence(ClassLabel(names=chunk_names)),\n","        \"ner_tags\": Sequence(ClassLabel(names=ner_names)),\n","    }\n",")\n","\n","train_examples = parse_conll(train_file)\n","valid_examples = parse_conll(valid_file)\n","test_examples = parse_conll(test_file)\n","\n","conll2003 = DatasetDict(\n","    {\n","        \"train\": as_dataset(train_examples, features),\n","        \"validation\": as_dataset(valid_examples, features),\n","        \"test\": as_dataset(test_examples, features),\n","    }\n",")\n","\n","display(conll2003)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2_ru3t1FgeQ"},"outputs":[],"source":["print(conll2003['train'][2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"maanNXNrFgeR"},"outputs":[],"source":["def load_glove_embeddings(file_path, embedding_dim):\n","    # dict to store word embed vectors\n","    word_vectors = {}\n","    with open(file_path, 'r', encoding='utf - 8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vector = torch.tensor(\n","                [float(val) for val in values[1:]], dtype=torch.float32)\n","            word_vectors[word] = vector\n","\n","    # matrix of embeddings\n","    vocab_size = len(word_vectors)\n","    embedding_matrix = torch.zeros((vocab_size, embedding_dim))\n","    word_to_idx = {}\n","    idx_to_word = {}\n","    for i, (word, vector) in enumerate(word_vectors.items()):\n","        embedding_matrix[i] = vector\n","        word_to_idx[word] = i\n","        idx_to_word[i] = word\n","\n","    return embedding_matrix, word_to_idx, idx_to_word\n","\n","\n","embedding_dim = 100\n","embedding_matrix, word_to_idx, idx_to_word = load_glove_embeddings(GLOVE_EMBEDS_PATH, embedding_dim)\n","\n","\n","embedding_layer = nn.Embedding.from_pretrained(embedding_matrix)\n","embedding_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CEY5bWDEFgeS"},"outputs":[],"source":["UNK_IDX = len(word_to_idx)\n","\n","def tokens_to_indices(tokens_batch):\n","    indices = []\n","    for tokens in tokens_batch:\n","        idxs = [\n","            word_to_idx.get(t.lower(), UNK_IDX) for t in tokens\n","        ]\n","        indices.append(torch.tensor(idxs, dtype=torch.long))\n","    return indices\n","\n","\n","def labels_to_tensors(labels_batch):\n","    return [torch.tensor(lbls, dtype=torch.long) for lbls in labels_batch]\n","\n","\n","def collate_fn(batch):\n","    input_ids = tokens_to_indices([b[\"tokens\"] for b in batch])\n","    labels = labels_to_tensors([b[\"ner_tags\"] for b in batch])\n","    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=UNK_IDX)\n","    labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n","    return {\"input_ids\": input_ids, \"labels\": labels}\n","\n","\n","train_dataloader = DataLoader(conll2003[\"train\"], batch_size=32, shuffle=True, collate_fn=collate_fn)\n","val_dataloader = DataLoader(conll2003[\"validation\"], batch_size=32, collate_fn=collate_fn)\n","test_dataloader = DataLoader(conll2003[\"test\"], batch_size=32, collate_fn=collate_fn)"]},{"cell_type":"code","source":["print(conll2003[\"train\"][0])"],"metadata":{"id":"yA7fpdW8J8Cg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 1.\n","  - Create a custom nn.Module class that takes Glove word embeddings as input, passes them through a linear layer, and outputs NER tags\n","  - Train the model using cross-entropy loss and evaluate its performance using entity-level F1 score\n","  - Analyze the model's predictions and visualize the confusion matrix to identify common errors"],"metadata":{"id":"Aoci_vRQP7sw"}},{"cell_type":"code","source":["ner_names = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n","tag_map   = {i: tag for i, tag in enumerate(ner_names)}\n","num_tags  = len(ner_names)\n","\n","class LinearNER(nn.Module):\n","    def __init__(self, embedding_matrix: torch.Tensor, num_tags: int):\n","\n","        super().__init__()\n","        vocab_size, embed_dim = embedding_matrix.shape\n","\n","        self.embedding = nn.Embedding(vocab_size + 1, embed_dim)\n","        with torch.no_grad():\n","            self.embedding.weight[:vocab_size].copy_(embedding_matrix)\n","            self.embedding.weight[vocab_size].zero_()\n","\n","        self.classifier = nn.Linear(embed_dim, num_tags)\n","\n","    def forward(self, input_ids):\n","        emb = self.embedding(input_ids)\n","        logits = self.classifier(emb)\n","        return logits\n","\n","def compute_metrics(predictions: torch.Tensor, labels: torch.Tensor, tag_map: dict):\n","\n","    if predictions.ndim > 1:\n","        predictions = predictions.view(-1)\n","    if labels.ndim > 1:\n","        labels = labels.view(-1)\n","\n","    mask = labels != -100\n","    if mask.sum().item() == 0:\n","        return 0.0, 0.0, 0.0\n","\n","    predictions = predictions[mask]\n","    labels = labels[mask]\n","\n","    pred_tags = [tag_map[int(p)] for p in predictions]\n","    true_tags = [tag_map[int(l)] for l in labels]\n","\n","    precision = precision_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","    recall = recall_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","    f1 = f1_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","\n","    return precision, recall, f1\n","\n","def train_linear_model(model, train_dataloader, val_dataloader, tag_map, num_epochs=3):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","    for epoch in range(num_epochs):\n","\n","        model.train()\n","        total_loss = 0.0\n","        total_preds, total_labels = [], []\n","\n","        train_bar = tqdm(train_dataloader,\n","                        desc=f\"Epoch {epoch+1}/{num_epochs} Training\",\n","                        unit=\"batch\")\n","        for b_idx, batch in enumerate(train_bar, start=1):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            optimizer.zero_grad()\n","            logits = model(input_ids)\n","            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            total_preds.append(preds.detach().cpu().view(-1))\n","            total_labels.append(labels.detach().cpu().view(-1))\n","\n","            running_preds = torch.cat(total_preds, dim=0)\n","            running_labels = torch.cat(total_labels, dim=0)\n","            _, _, running_f1 = compute_metrics(running_preds, running_labels, tag_map)\n","            train_bar.set_postfix(loss=f\"{(total_loss/b_idx):.3f}\", F1=f\"{running_f1:.3f}\")\n","\n","        _, _, epoch_train_f1 = compute_metrics(torch.cat(total_preds), torch.cat(total_labels), tag_map)\n","        print(f\"Epoch {epoch+1} Training - Loss: {total_loss/len(train_dataloader):.4f}, F1: {epoch_train_f1:.4f}\")\n","\n","        model.eval()\n","        val_loss = 0.0\n","        val_preds, val_labels = [], []\n","\n","        val_bar = tqdm(val_dataloader,\n","                      desc=f\"Epoch {epoch+1}/{num_epochs} Validation\",\n","                      unit=\"batch\")\n","        with torch.no_grad():\n","            for batch in val_bar:\n","                input_ids = batch[\"input_ids\"].to(device)\n","                labels = batch[\"labels\"].to(device)\n","\n","                logits = model(input_ids)\n","                loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","                val_loss += loss.item()\n","\n","                preds = torch.argmax(logits, dim=-1)\n","                val_preds.append(preds.detach().cpu().view(-1))\n","                val_labels.append(labels.detach().cpu().view(-1))\n","\n","        _, _, epoch_val_f1 = compute_metrics(torch.cat(val_preds), torch.cat(val_labels), tag_map)\n","        print(f\"Epoch {epoch+1} Validation - Loss: {val_loss/len(val_dataloader):.4f}, F1 {epoch_val_f1:.4f}\\n\")\n","\n","    return model\n","\n","def evaluate_on_test(model, test_dataloader, tag_map):\n","    \"\"\"Valuta il modello sul test set e restituisce predizioni e metriche.\"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","    test_loss = 0.0\n","    test_preds, test_labels = [], []\n","\n","    test_bar = tqdm(test_dataloader, desc=\"Testing\", unit=\"batch\")\n","    with torch.no_grad():\n","        for batch in test_bar:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            logits = model(input_ids)\n","            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","            test_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            test_preds.append(preds.cpu().view(-1))\n","            test_labels.append(labels.cpu().view(-1))\n","\n","    test_preds_flat = torch.cat(test_preds)\n","    test_labels_flat = torch.cat(test_labels)\n","\n","    precision, recall, f1 = compute_metrics(test_preds_flat, test_labels_flat, tag_map)\n","\n","    print(f\"\\nTest Results:\")\n","    print(f\"  Loss: {test_loss/len(test_dataloader):.4f}\")\n","    print(f\"  Precision: {precision:.4f}\")\n","    print(f\"  Recall: {recall:.4f}\")\n","    print(f\"  F1: {f1:.4f}\")\n","\n","    test_preds_list = [int(x) for x in test_preds_flat.tolist()]\n","    test_labels_list = [int(x) for x in test_labels_flat.tolist()]\n","\n","    return test_preds_list, test_labels_list, precision, recall, f1\n","\n","def analyze_predictions(predictions, labels, tag_map):\n","    \"\"\"Analizza e stampa report + errori comuni (ignora padding -100).\"\"\"\n","    labels_np = np.asarray(labels)\n","    preds_np  = np.asarray(predictions)\n","    mask = labels_np != -100\n","\n","    pred_filtered  = preds_np[mask]\n","    label_filtered = labels_np[mask]\n","\n","    pred_tags  = [tag_map[p] for p in pred_filtered]\n","    true_tags  = [tag_map[l] for l in label_filtered]\n","\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"CLASSIFICATION REPORT:\")\n","    print(\"=\" * 70)\n","    print(classification_report(true_tags, pred_tags, zero_division=0))\n","\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"ERRORI PIÃ™ COMUNI:\")\n","    print(\"=\" * 70)\n","    errors = {}\n","    for t, p in zip(true_tags, pred_tags):\n","        if t != p:\n","            key = f\"{t} -> {p}\"\n","            errors[key] = errors.get(key, 0) + 1\n","    for error, count in sorted(errors.items(), key=lambda x: x[1], reverse=True)[:10]:\n","        print(f\"{error:20s}: {count:5d} errori\")\n","\n","    return pred_filtered, label_filtered\n","\n","def plot_confusion_matrix(predictions, labels, tag_map):\n","\n","    labels_np = np.asarray(labels)\n","    preds_np  = np.asarray(predictions)\n","    mask = labels_np != -100\n","\n","    pred_filtered  = preds_np[mask]\n","    label_filtered = labels_np[mask]\n","\n","    cm = confusion_matrix(label_filtered, pred_filtered)\n","    tags = list(tag_map.values())\n","\n","    plt.figure(figsize=(12, 10))\n","    cm_norm = cm.astype('float') / (cm.sum(axis=1, keepdims=True) + 1e-12)\n","    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n","                xticklabels=tags, yticklabels=tags,\n","                cbar_kws={'label': 'Proporzione'})\n","    plt.title('Confusion Matrix - Modello Lineare NER (Normalizzata)', fontsize=14, pad=20)\n","    plt.ylabel('True Label', fontsize=12)\n","    plt.xlabel('Predicted Label', fontsize=12)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.yticks(rotation=0)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    plt.figure(figsize=(12, 10))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n","                xticklabels=tags, yticklabels=tags,\n","                cbar_kws={'label': 'Count'})\n","    plt.title('Confusion Matrix - Modello Lineare NER (Counts)', fontsize=14, pad=20)\n","    plt.ylabel('True Label', fontsize=12)\n","    plt.xlabel('Predicted Label', fontsize=12)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.yticks(rotation=0)\n","    plt.tight_layout()\n","    plt.show()\n","\n","linear_model = LinearNER(embedding_matrix, num_tags)\n","\n","print(\"\\nTraining del modello lineare...\")\n","linear_model = train_linear_model(\n","    linear_model, train_dataloader, val_dataloader, tag_map, num_epochs=3\n",")\n","\n","print(\"\\n\\nValutazione sul Test Set...\")\n","test_preds, test_labels, linear_precision, linear_recall, linear_f1 = evaluate_on_test(\n","    linear_model, test_dataloader, tag_map\n",")\n","\n","print(\"\\n\\nAnalisi delle predizioni sul test set...\")\n","pred_filtered, label_filtered = analyze_predictions(test_preds, test_labels, tag_map)\n","\n","print(\"\\n\\nGenerazione Confusion Matrix...\")\n","plot_confusion_matrix(test_preds, test_labels, tag_map)"],"metadata":{"id":"Zl1pLVkFOfnl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 2. Build a multi-layer perceptron (MLP) for NER using Glove embeddings\n","   - Extend the previous exercise by creating an nn.Module class that defines an MLP architecture on top of Glove embeddings\n","   - Experiment with different hidden layer sizes and number of layers\n","   - Evaluate the trained model using entity-level precision, recall, and F1 scores\n","   - Compare the performance of the MLP model with the simple linear model from exercise 1"],"metadata":{"id":"iWaeQYRgPsgh"}},{"cell_type":"code","source":["class MLPNER(nn.Module):\n","    def __init__(self, embedding_matrix: torch.Tensor, num_tags: int,\n","                 hidden_sizes=[256, 128], dropout=0.3):\n","\n","        super(MLPNER, self).__init__()\n","        vocab_size, embed_dim = embedding_matrix.shape\n","\n","        self.embedding = nn.Embedding(vocab_size + 1, embed_dim)\n","        with torch.no_grad():\n","            self.embedding.weight[:vocab_size].copy_(embedding_matrix)\n","            self.embedding.weight[vocab_size].zero_()\n","\n","        layers = []\n","        input_size = embed_dim\n","\n","        for hidden_size in hidden_sizes:\n","            layers.append(nn.Linear(input_size, hidden_size))\n","            layers.append(nn.ReLU())\n","            layers.append(nn.Dropout(dropout))\n","            input_size = hidden_size\n","\n","        layers.append(nn.Linear(input_size, num_tags))\n","\n","        self.mlp = nn.Sequential(*layers)\n","\n","    def forward(self, input_ids):\n","        emb = self.embedding(input_ids)  # (B, T, D)\n","        logits = self.mlp(emb)           # (B, T, num_tags)\n","        return logits\n","\n","\n","def compute_metrics(predictions, labels, tag_map):\n","\n","    if predictions.ndim > 1:\n","        predictions = predictions.view(-1)\n","    if labels.ndim > 1:\n","        labels = labels.view(-1)\n","\n","    mask = labels != -100\n","    if mask.sum().item() == 0:\n","        return 0.0, 0.0, 0.0\n","\n","    predictions = predictions[mask]\n","    labels = labels[mask]\n","\n","    pred_tags = [tag_map[int(p)] for p in predictions]\n","    true_tags = [tag_map[int(l)] for l in labels]\n","\n","    precision = precision_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","    recall = recall_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","    f1 = f1_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","\n","    return precision, recall, f1\n","\n","def train_mlp_model(model, train_dataloader, val_dataloader, tag_map, num_epochs=3):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","    for epoch in range(num_epochs):\n","\n","        model.train()\n","        train_loss = 0.0\n","        train_preds, train_labels = [], []\n","\n","        train_bar = tqdm(train_dataloader,\n","                        desc=f\"Epoch {epoch+1}/{num_epochs} Training\",\n","                        unit=\"batch\")\n","        for b_idx, batch in enumerate(train_bar, start=1):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            optimizer.zero_grad()\n","            logits = model(input_ids)\n","            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            train_preds.append(preds.detach().cpu().view(-1))\n","            train_labels.append(labels.detach().cpu().view(-1))\n","\n","            running_preds = torch.cat(train_preds, dim=0)\n","            running_labels = torch.cat(train_labels, dim=0)\n","            _, _, running_f1 = compute_metrics(running_preds, running_labels, tag_map)\n","            train_bar.set_postfix(loss=f\"{(train_loss/b_idx):.3f}\", F1=f\"{running_f1:.3f}\")\n","\n","        _, _, train_f1 = compute_metrics(torch.cat(train_preds), torch.cat(train_labels), tag_map)\n","        print(f\"Epoch {epoch+1} Training - Loss: {train_loss/len(train_dataloader):.4f}, F1: {train_f1:.4f}\")\n","\n","        model.eval()\n","        val_loss = 0.0\n","        val_preds, val_labels = [], []\n","\n","        val_bar = tqdm(val_dataloader,\n","                      desc=f\"Epoch {epoch+1}/{num_epochs} Validation\",\n","                      unit=\"batch\")\n","        with torch.no_grad():\n","            for batch in val_bar:\n","                input_ids = batch[\"input_ids\"].to(device)\n","                labels = batch[\"labels\"].to(device)\n","\n","                logits = model(input_ids)\n","                loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","                val_loss += loss.item()\n","\n","                preds = torch.argmax(logits, dim=-1)\n","                val_preds.append(preds.cpu().view(-1))\n","                val_labels.append(labels.cpu().view(-1))\n","\n","        _, _, val_f1 = compute_metrics(torch.cat(val_preds), torch.cat(val_labels), tag_map)\n","        print(f\"Epoch {epoch+1} Validation - Loss: {val_loss/len(val_dataloader):.4f}, F1 {val_f1:.4f}\\n\")\n","\n","    return model\n","\n","def evaluate_on_test(model, test_dataloader, tag_map):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","    test_loss = 0.0\n","    test_preds, test_labels = [], []\n","\n","    test_bar = tqdm(test_dataloader, desc=\"Testing\", unit=\"batch\")\n","    with torch.no_grad():\n","        for batch in test_bar:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            logits = model(input_ids)\n","            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","            test_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            test_preds.append(preds.cpu().view(-1))\n","            test_labels.append(labels.cpu().view(-1))\n","\n","    test_preds_flat = torch.cat(test_preds)\n","    test_labels_flat = torch.cat(test_labels)\n","\n","    precision, recall, f1 = compute_metrics(test_preds_flat, test_labels_flat, tag_map)\n","\n","    print(f\"Test Results - Loss: {test_loss/len(test_dataloader):.4f}, \"\n","          f\"P: {precision:.4f}, R: {recall:.4f}, F1: {f1:.4f}\")\n","\n","    return precision, recall, f1\n","\n","configs = [\n","    {\"name\": \"MLP-Small\", \"hidden_sizes\": [128], \"dropout\": 0.2},\n","    {\"name\": \"MLP-Medium\", \"hidden_sizes\": [256, 128], \"dropout\": 0.3},\n","    {\"name\": \"MLP-Large\", \"hidden_sizes\": [512, 256, 128], \"dropout\": 0.3},\n","    {\"name\": \"MLP-XLarge\", \"hidden_sizes\": [1024, 512, 256, 128], \"dropout\": 0.3},\n","]\n","\n","mlp_results = {}\n","\n","for config in configs:\n","    print(f\"\\n\\nAddestramento {config['name']}...\")\n","    print(f\"Architettura: {config['hidden_sizes']}, Dropout: {config['dropout']}\")\n","\n","    model = MLPNER(\n","        embedding_matrix,\n","        num_tags,\n","        hidden_sizes=config['hidden_sizes'],\n","        dropout=config['dropout']\n","    )\n","\n","    model = train_mlp_model(model, train_dataloader, val_dataloader, tag_map, num_epochs=3)\n","\n","    print(f\"\\nValutazione {config['name']} sul Test Set...\")\n","    precision, recall, f1 = evaluate_on_test(model, test_dataloader, tag_map)\n","\n","    mlp_results[config['name']] = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'hidden_sizes': config['hidden_sizes']\n","    }\n","\n","mlp_results['Linear'] = {\n","    'precision': linear_precision,\n","    'recall': linear_recall,\n","    'f1': linear_f1,\n","    'hidden_sizes': None\n","}\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CONFRONTO PERFORMANCE SUL TEST SET:\")\n","print(\"=\" * 70)\n","for name, results in mlp_results.items():\n","    print(f\"{name:15s} - F1: {results['f1']:.4f}, \"\n","          f\"P: {results['precision']:.4f}, R: {results['recall']:.4f}\")\n","\n","fig, ax = plt.subplots(figsize=(14, 8))\n","\n","models = list(mlp_results.keys())\n","f1_scores = [mlp_results[m]['f1'] for m in models]\n","precision_scores = [mlp_results[m]['precision'] for m in models]\n","recall_scores = [mlp_results[m]['recall'] for m in models]\n","\n","x = np.arange(len(models))\n","width = 0.25\n","\n","bars1 = ax.bar(x - width, f1_scores, width, label='F1', color='#3498db', alpha=0.8)\n","bars2 = ax.bar(x, precision_scores, width, label='Precision', color='#2ecc71', alpha=0.8)\n","bars3 = ax.bar(x + width, recall_scores, width, label='Recall', color='#e74c3c', alpha=0.8)\n","\n","ax.set_xlabel('Modelli', fontsize=12, fontweight='bold')\n","ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n","ax.set_title('Confronto Performance dei Modelli sul Test Set', fontsize=14, fontweight='bold', pad=20)\n","ax.set_xticks(x)\n","ax.set_xticklabels(models, rotation=15, ha='right')\n","ax.legend(fontsize=11)\n","ax.grid(axis='y', alpha=0.3, linestyle='--')\n","ax.set_ylim([0, 1])\n","\n","for bars in [bars1, bars2, bars3]:\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax.text(bar.get_x() + bar.get_width()/2., height,\n","                f'{height:.3f}',\n","                ha='center', va='bottom', fontsize=9)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","best_model_name = max(mlp_results.items(), key=lambda x: x[1]['f1'])[0]\n","best_f1 = mlp_results[best_model_name]['f1']\n","best_hidden_sizes = mlp_results[best_model_name]['hidden_sizes']\n","\n","print(f\"\\nðŸ† Modello migliore: {best_model_name} con F1 = {best_f1:.4f}\")\n","if best_hidden_sizes:\n","    print(f\"   Architettura: {best_hidden_sizes}\")"],"metadata":{"id":"cRB_drl-PsO4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 3. Explore the effects of different activation functions and regularization techniques for NER\n","  - Modify the MLP model from exercise 2 to allow configurable activation functions (e.g. ReLU, tanh, sigmoid)\n","  - Train models with different activation functions.\n","  - Visualize the learned entity embeddings using dimensionality reduction techniques like PCA or t-SNE (edited)"],"metadata":{"id":"MkfZzwOhPnL1"}},{"cell_type":"code","source":["class ConfigurableMLPNER(nn.Module):\n","    def __init__(self, embedding_matrix: torch.Tensor, num_tags: int,\n","                 hidden_sizes=[256, 128], dropout=0.3, activation='relu'):\n","\n","        super(ConfigurableMLPNER, self).__init__()\n","        vocab_size, embed_dim = embedding_matrix.shape\n","\n","        self.embedding = nn.Embedding(vocab_size + 1, embed_dim)\n","        with torch.no_grad():\n","            self.embedding.weight[:vocab_size].copy_(embedding_matrix)\n","            self.embedding.weight[vocab_size].zero_()\n","\n","        activation_functions = {\n","            'relu': nn.ReLU,\n","            'tanh': nn.Tanh,\n","            'sigmoid': nn.Sigmoid,\n","            'gelu': nn.GELU,\n","            'logistic': nn.Sigmoid\n","        }\n","\n","        if activation not in activation_functions:\n","            raise ValueError(f\"Activation deve essere una tra: {list(activation_functions.keys())}\")\n","\n","        act_class = activation_functions[activation]\n","\n","        layers = []\n","        input_size = embed_dim\n","\n","        for hidden_size in hidden_sizes:\n","            layers.append(nn.Linear(input_size, hidden_size))\n","            layers.append(act_class())\n","            layers.append(nn.Dropout(dropout))\n","            input_size = hidden_size\n","\n","        layers.append(nn.Linear(input_size, num_tags))\n","        self.mlp = nn.Sequential(*layers)\n","\n","    def forward(self, input_ids):\n","        emb = self.embedding(input_ids)\n","        logits = self.mlp(emb)\n","        return logits\n","\n","def compute_metrics(predictions, labels, tag_map):\n","\n","    if predictions.ndim > 1:\n","        predictions = predictions.view(-1)\n","    if labels.ndim > 1:\n","        labels = labels.view(-1)\n","\n","    mask = labels != -100\n","    if mask.sum().item() == 0:\n","        return 0.0, 0.0, 0.0\n","\n","    predictions = predictions[mask]\n","    labels = labels[mask]\n","\n","    pred_tags = [tag_map[int(p)] for p in predictions]\n","    true_tags = [tag_map[int(l)] for l in labels]\n","\n","    precision = precision_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","    recall = recall_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","    f1 = f1_score(true_tags, pred_tags, average='weighted', zero_division=0)\n","\n","    return precision, recall, f1\n","\n","def train_model(model, train_dataloader, val_dataloader, tag_map, num_epochs=3):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","    for epoch in range(num_epochs):\n","\n","        model.train()\n","        train_loss = 0.0\n","        train_preds, train_labels = [], []\n","\n","        train_bar = tqdm(train_dataloader,\n","                        desc=f\"Epoch {epoch+1}/{num_epochs} Training\",\n","                        unit=\"batch\")\n","        for b_idx, batch in enumerate(train_bar, start=1):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            optimizer.zero_grad()\n","            logits = model(input_ids)\n","            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            train_preds.append(preds.detach().cpu().view(-1))\n","            train_labels.append(labels.detach().cpu().view(-1))\n","\n","            running_preds = torch.cat(train_preds, dim=0)\n","            running_labels = torch.cat(train_labels, dim=0)\n","            _, _, running_f1 = compute_metrics(running_preds, running_labels, tag_map)\n","            train_bar.set_postfix(loss=f\"{(train_loss/b_idx):.3f}\", F1=f\"{running_f1:.3f}\")\n","\n","        _, _, train_f1 = compute_metrics(torch.cat(train_preds), torch.cat(train_labels), tag_map)\n","        print(f\"Epoch {epoch+1} Training - Loss: {train_loss/len(train_dataloader):.4f}, F1: {train_f1:.4f}\")\n","\n","        model.eval()\n","        val_loss = 0.0\n","        val_preds, val_labels = [], []\n","\n","        val_bar = tqdm(val_dataloader,\n","                      desc=f\"Epoch {epoch+1}/{num_epochs} Validation\",\n","                      unit=\"batch\")\n","        with torch.no_grad():\n","            for batch in val_bar:\n","                input_ids = batch[\"input_ids\"].to(device)\n","                labels = batch[\"labels\"].to(device)\n","\n","                logits = model(input_ids)\n","                loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","                val_loss += loss.item()\n","\n","                preds = torch.argmax(logits, dim=-1)\n","                val_preds.append(preds.cpu().view(-1))\n","                val_labels.append(labels.cpu().view(-1))\n","\n","        _, _, val_f1 = compute_metrics(torch.cat(val_preds), torch.cat(val_labels), tag_map)\n","        print(f\"Epoch {epoch+1} Validation - Loss: {val_loss/len(val_dataloader):.4f}, F1 {val_f1:.4f}\\n\")\n","\n","    return model\n","\n","def evaluate_on_test(model, test_dataloader, tag_map):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","    test_loss = 0.0\n","    test_preds, test_labels = [], []\n","\n","    test_bar = tqdm(test_dataloader, desc=\"Testing\", unit=\"batch\")\n","    with torch.no_grad():\n","        for batch in test_bar:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            logits = model(input_ids)\n","            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","            test_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            test_preds.append(preds.cpu().view(-1))\n","            test_labels.append(labels.cpu().view(-1))\n","\n","    test_preds_flat = torch.cat(test_preds)\n","    test_labels_flat = torch.cat(test_labels)\n","\n","    precision, recall, f1 = compute_metrics(test_preds_flat, test_labels_flat, tag_map)\n","\n","    print(f\"Test Results - Loss: {test_loss/len(test_dataloader):.4f}, \"\n","          f\"P: {precision:.4f}, R: {recall:.4f}, F1: {f1:.4f}\")\n","\n","    return model, precision, recall, f1\n","\n","print(f\"\\nUtilizzo l'architettura del modello migliore dell'esercizio 2: {best_model_name}\")\n","if best_hidden_sizes:\n","    print(f\"Architettura hidden layers: {best_hidden_sizes}\")\n","    use_hidden_sizes = best_hidden_sizes\n","else:\n","\n","    use_hidden_sizes = [256, 128]\n","    print(f\"Il modello lineare ha vinto. Uso architettura di default: {use_hidden_sizes}\")\n","\n","activations = ['relu', 'tanh', 'sigmoid', 'gelu', 'logistic']\n","activation_results = {}\n","\n","for act in activations:\n","    print(f\"\\n\\nAddestramento con activation={act}...\")\n","\n","    model = ConfigurableMLPNER(\n","        embedding_matrix,\n","        num_tags,\n","        hidden_sizes=use_hidden_sizes,\n","        dropout=0.3,\n","        activation=act\n","    )\n","\n","    model = train_model(model, train_dataloader, val_dataloader, tag_map, num_epochs=3)\n","\n","    print(f\"\\nValutazione {act} sul Test Set...\")\n","    model, precision, recall, f1 = evaluate_on_test(model, test_dataloader, tag_map)\n","\n","    activation_results[act] = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'model': model\n","    }\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CONFRONTO ACTIVATION FUNCTIONS SUL TEST SET:\")\n","print(\"=\" * 70)\n","for act, results in activation_results.items():\n","    print(f\"{act.upper():10s} - F1: {results['f1']:.4f}, \"\n","          f\"P: {results['precision']:.4f}, R: {results['recall']:.4f}\")\n","\n","fig, ax = plt.subplots(figsize=(14, 8))\n","\n","activations_list = list(activation_results.keys())\n","f1_scores = [activation_results[a]['f1'] for a in activations_list]\n","precision_scores = [activation_results[a]['precision'] for a in activations_list]\n","recall_scores = [activation_results[a]['recall'] for a in activations_list]\n","\n","x = np.arange(len(activations_list))\n","width = 0.25\n","\n","bars1 = ax.bar(x - width, f1_scores, width, label='F1', color='#9b59b6', alpha=0.8)\n","bars2 = ax.bar(x, precision_scores, width, label='Precision', color='#f39c12', alpha=0.8)\n","bars3 = ax.bar(x + width, recall_scores, width, label='Recall', color='#1abc9c', alpha=0.8)\n","\n","ax.set_xlabel('Activation Functions', fontsize=12, fontweight='bold')\n","ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n","ax.set_title('Confronto Activation Functions sul Test Set', fontsize=14, fontweight='bold', pad=20)\n","ax.set_xticks(x)\n","ax.set_xticklabels([a.upper() for a in activations_list], rotation=0)\n","ax.legend(fontsize=11)\n","ax.grid(axis='y', alpha=0.3, linestyle='--')\n","ax.set_ylim([0, 1])\n","\n","for bars in [bars1, bars2, bars3]:\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax.text(bar.get_x() + bar.get_width()/2., height,\n","                f'{height:.3f}',\n","                ha='center', va='bottom', fontsize=9)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","best_activation = max(activation_results.items(), key=lambda x: x[1]['f1'])[0]\n","best_act_f1 = activation_results[best_activation]['f1']\n","print(f\"\\nðŸ† Migliore activation function: {best_activation.upper()} con F1 = {best_act_f1:.4f}\")\n","\n","def extract_entity_embeddings(model, dataloader, tag_map, device):\n","    \"\"\"Estrae gli embeddings per ogni tipo di entitÃ \"\"\"\n","    model.eval()\n","    entity_embeddings = {tag: [] for tag in tag_map.values() if tag != 'O'}\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Estrazione embeddings\"):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            emb = model.embedding(input_ids)\n","\n","            for i in range(emb.shape[0]):\n","                for j in range(emb.shape[1]):\n","                    label_idx = labels[i, j].item()\n","                    if label_idx != -100:\n","                        tag = tag_map[label_idx]\n","                        if tag != 'O':\n","                            entity_embeddings[tag].append(emb[i, j].cpu().numpy())\n","\n","    return entity_embeddings\n","\n","\n","def visualize_embeddings(entity_embeddings, method='pca', n_samples=500):\n","\n","    all_embeddings = []\n","    all_labels = []\n","\n","    for tag, embeddings in entity_embeddings.items():\n","        if len(embeddings) > 0:\n","            samples = np.array(embeddings[:n_samples])\n","            all_embeddings.append(samples)\n","            all_labels.extend([tag] * len(samples))\n","\n","    if len(all_embeddings) == 0:\n","        print(\"Nessun embedding da visualizzare!\")\n","        return\n","\n","    all_embeddings = np.vstack(all_embeddings)\n","\n","    if method == 'pca':\n","        reducer = PCA(n_components=2)\n","        reduced = reducer.fit_transform(all_embeddings)\n","        title = f'PCA - Entity Embeddings (variance: {reducer.explained_variance_ratio_.sum():.2%})'\n","    else:\n","        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n","        reduced = reducer.fit_transform(all_embeddings)\n","        title = 't-SNE - Entity Embeddings'\n","\n","    plt.figure(figsize=(12, 8))\n","    unique_labels = list(set(all_labels))\n","    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n","\n","    for label, color in zip(unique_labels, colors):\n","        mask = np.array(all_labels) == label\n","        plt.scatter(reduced[mask, 0], reduced[mask, 1],\n","                   c=[color], label=label, alpha=0.6, s=30)\n","\n","    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.title(title, fontsize=14, fontweight='bold')\n","    plt.xlabel('Component 1', fontsize=12)\n","    plt.ylabel('Component 2', fontsize=12)\n","    plt.tight_layout()\n","    plt.show()\n","\n","print(\"\\n\\nVisualizzazione Entity Embeddings...\")\n","best_viz_model = activation_results[best_activation]['model']\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","entity_embeddings = extract_entity_embeddings(best_viz_model, val_dataloader, tag_map, device)\n","\n","print(\"\\nGenerazione plot PCA...\")\n","visualize_embeddings(entity_embeddings, method='pca')\n","\n","print(\"\\nGenerazione plot t-SNE...\")\n","visualize_embeddings(entity_embeddings, method='tsne')"],"metadata":{"id":"ljufHEVzQPrH"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"NLP_VENV","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}